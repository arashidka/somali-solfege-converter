{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Somali Solfege Converter - Audio Processing\n",
    "\n",
    "## PRSE (Python Rapid-Systems Engine) Mode\n",
    "\n",
    "This notebook implements **Phase 1: Initialization** of the Somali Solfege Converter system.\n",
    "\n",
    "### Design Blueprint: Phase 1\n",
    "\n",
    "* **Architectural Choice:** Procedural (Linear pipeline is most efficient for this automation)\n",
    "* **Key Libraries:** `moviepy` (Video handling), `scipy` (I/O), `numpy` (DSP)\n",
    "* **Memory Strategy:** Immediate conversion to `float32` and deletion of video objects after audio extraction\n",
    "* **Target Sample Rate:** 22.05kHz for memory efficiency on 8GB RAM systems\n",
    "\n",
    "### Supported Formats\n",
    "\n",
    "* **Video:** .mp4, .mov, .avi, .mkv (audio will be extracted automatically)\n",
    "* **Audio:** .wav, .mp3, .flac, .ogg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Environment & Dependencies\n",
    "\n",
    "This cell ensures your virtual environment is ready and all required libraries are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# List of required libraries\n",
    "libraries = ['moviepy', 'numpy', 'scipy', 'matplotlib', 'librosa']\n",
    "\n",
    "def check_setup():\n",
    "    print(\"Checking environment dependencies...\")\n",
    "    for lib in libraries:\n",
    "        try:\n",
    "            __import__(lib)\n",
    "            print(f\"✅ {lib} is installed.\")\n",
    "        except ImportError:\n",
    "            print(f\"❌ {lib} missing. Installing now...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", lib])\n",
    "\n",
    "check_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Audio Extraction & Pre-processing\n",
    "\n",
    "This cell detects if your input is a video and extracts the audio stream, or loads an audio file directly. \n",
    "It performs the **22.05kHz downsampling** for memory efficiency.\n",
    "\n",
    "### Features:\n",
    "* Automatic video-to-audio extraction\n",
    "* Stereo-to-mono conversion\n",
    "* Downsampling to 22.05kHz\n",
    "* Memory-efficient float32 normalization\n",
    "* Automatic cleanup of temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Import moviepy - compatible with both v1.x and v2.x\n",
    "try:\n",
    "    from moviepy import VideoFileClip\n",
    "except ImportError:\n",
    "    from moviepy.editor import VideoFileClip\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "def prepare_audio_input(file_path, target_sr=22050):\n",
    "    \"\"\"\n",
    "    Extracts audio from video if needed and loads it into memory.\n",
    "    Optimized for 8GB RAM using float32 and downsampling.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    temp_audio = \"temp_extracted_audio.wav\"\n",
    "    \n",
    "    # Step 1: Video to Audio Extraction (If needed)\n",
    "    if ext in ['.mp4', '.mov', '.avi', '.mkv']:\n",
    "        print(f\"Video detected. Extracting audio from {file_path}...\")\n",
    "        video = VideoFileClip(file_path)\n",
    "        video.audio.write_audiofile(temp_audio, fps=target_sr, verbose=False, logger=None)\n",
    "        video.close() # Close file handle immediately\n",
    "        load_path = temp_audio\n",
    "        del video\n",
    "    else:\n",
    "        load_path = file_path\n",
    "\n",
    "    # Step 2: Load and Downsample\n",
    "    print(f\"Loading and normalizing audio...\")\n",
    "    sr, data = wavfile.read(load_path)\n",
    "    \n",
    "    # Convert to Mono if Stereo\n",
    "    if len(data.shape) > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    \n",
    "    # Downsample logic (Simple decimation for speed)\n",
    "    if sr != target_sr:\n",
    "        resample_factor = max(1, sr // target_sr)\n",
    "        data = data[::resample_factor]\n",
    "    \n",
    "    # Memory-safe conversion\n",
    "    samples = data.astype(np.float32)\n",
    "    samples /= np.max(np.abs(samples)) if np.max(np.abs(samples)) > 0 else 1.0\n",
    "    \n",
    "    # Cleanup\n",
    "    if os.path.exists(temp_audio) and ext in ['.mp4', '.mov', '.avi', '.mkv']:\n",
    "        os.remove(temp_audio)\n",
    "    \n",
    "    del data\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"Done. Loaded {len(samples)/target_sr:.2f}s of audio at {target_sr}Hz.\")\n",
    "    return samples, target_sr\n",
    "\n",
    "# --- TEST THE CELL ---\n",
    "# Uncomment the lines below and provide your input file path\n",
    "# INPUT_FILE = \"your_video_or_audio_here.mp4\" \n",
    "# samples, sr = prepare_audio_input(INPUT_FILE)\n",
    "print(\"Audio extraction function ready. Set INPUT_FILE and run to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Visualize Audio Waveform (Optional)\n",
    "\n",
    "Once you have loaded audio, you can visualize it to verify the extraction worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_waveform(samples, sr, duration_limit=10.0):\n",
    "    \"\"\"\n",
    "    Plot the audio waveform.\n",
    "    \n",
    "    Args:\n",
    "        samples: Audio samples array\n",
    "        sr: Sample rate\n",
    "        duration_limit: Maximum duration to plot in seconds (default: 10s)\n",
    "    \"\"\"\n",
    "    # Limit the plot to avoid memory issues\n",
    "    max_samples = int(duration_limit * sr)\n",
    "    plot_samples = samples[:max_samples]\n",
    "    \n",
    "    time = np.arange(len(plot_samples)) / sr\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(time, plot_samples, linewidth=0.5)\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(f'Audio Waveform (first {duration_limit}s)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- VISUALIZE AUDIO ---\n",
    "# Uncomment to visualize after loading audio\n",
    "# plot_waveform(samples, sr)\n",
    "print(\"Waveform visualization function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Phase 2 - Pitch Detection\n",
    "\n",
    "The next phase will implement:\n",
    "1. **YIN Algorithm** for pitch detection\n",
    "2. **Note Segmentation** to identify individual notes\n",
    "3. **Somali Pentatonic Scale Mapping** for solfege conversion\n",
    "\n",
    "This will allow the system to analyze the musical content and convert it to Somali solfege notation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
